{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we\n",
    "will discuss a simple, nonlinear model for classification and regression tasks: the\n",
    "decision tree. We'll use decision trees to build an ad blocker that can learn to classify\n",
    "images on a web page as banner advertisements or page content. Finally, we will\n",
    "introduce ensemble learning methods, which combine a set of models to produce an\n",
    "estimator with better predictive performance than any of its component estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use decision trees to create software that can block banner ads on web pages.\n",
    "This program will predict whether each of the images on a web page is an\n",
    "advertisement or article content. Images that are classified as being advertisements\n",
    "could then be hidden using Cascading Style Sheets. We will train a decision tree\n",
    "classifier using the Internet Advertisements Data Set from http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements, which contains data for 3,279 images.\n",
    "The proportions of the classes are skewed; 459 of the images are advertisements and\n",
    "2,820 are content. Decision tree learning algorithms can produce biased trees from data\n",
    "with unbalanced class proportions; we will evaluate a model on the unaltered data set\n",
    "before deciding if it is worth balancing the training data by over- or under-sampling\n",
    "instances. The explanatory variables are the dimensions of the image, words from the\n",
    "containing page's URL, words from the image's URL, the image's alt text, the image's\n",
    "anchor text, and a window of words surrounding the image tag. The response variable\n",
    "is the image's class. The explanatory variables have already been transformed into\n",
    "feature representations. The first three features are real numbers that encode the width,\n",
    "height, and aspect ratio of the images. The remaining features encode binary term\n",
    "frequencies for the text variables. In the following sample, we will grid search for the\n",
    "hyperparameter values that produce the decision tree with the greatest accuracy,\n",
    "and then evaluate the tree's performance on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['99A14FBC9F5F453C90E5BD8018ADA22D']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['99A14FBC9F5F453C90E5BD8018ADA22D'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.If object>], cell_name='<ipython-input-3-628a811f7bea>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>\n        result = <ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>, result=<ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', '__': '', ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', '__': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Satvik Sachdev\\Documents\\GitHub\\Machine Learning\\Mastering Machine Learning with Scikit Learn\\Chapter 5 Nonlinear Classification and Regression with Decision Trees\\<ipython-input-3-628a811f7bea> in <module>()\n     40             'clf__min_samples_leaf': (1, 2, 3)\n     41             }\n     42     \n     43     # set GridSearchCV to maximise the models f1 score\n     44     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n---> 45     grid_search.fit(X_train, y_train)\n     46     print 'Best score: %0.3f' % grid_search.best_score_\n     47     print 'Best parameters set:'\n     48     best_parameters = grid_search.best_estimator_.get_params()\n     49     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...]\n        self.param_grid = {'clf__max_depth': (150, 155, 160), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul 01 15:09:02 2017\nPID: 17600               Python 2.7.13: C:\\ProgramData\\Anaconda2\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 806,  807,  808, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), 1, {'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 806,  807,  808, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), 1, {'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 806,  807,  808, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), verbose=1, parameters={'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rt=False, random_state=None, splitter='best'))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...esort=False, random_state=None, splitter='best')>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, check_input=True, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=array([[ 77.        ,  77.        ,   1.        ...       0.        ,   0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-628a811f7bea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# set GridSearchCV to maximise the models f1 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m                 for train, test in cv)\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['99A14FBC9F5F453C90E5BD8018ADA22D']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['99A14FBC9F5F453C90E5BD8018ADA22D'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 8, 51, 814000, tzinfo=tzutc()), u'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4F5A6B4786D64796B5E2A6A6237AE4D4', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.If object>], cell_name='<ipython-input-3-628a811f7bea>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>\n        result = <ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>, result=<ExecutionResult object at 105e2fd0, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000FB66330, file \"<ipython-input-3-628a811f7bea>\", line 8>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', '__': '', ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', '__': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Satvik Sachdev\\Documents\\GitHub\\Machine Learning\\Mastering Machine Learning with Scikit Learn\\Chapter 5 Nonlinear Classification and Regression with Decision Trees\\<ipython-input-3-628a811f7bea> in <module>()\n     40             'clf__min_samples_leaf': (1, 2, 3)\n     41             }\n     42     \n     43     # set GridSearchCV to maximise the models f1 score\n     44     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n---> 45     grid_search.fit(X_train, y_train)\n     46     print 'Best score: %0.3f' % grid_search.best_score_\n     47     print 'Best parameters set:'\n     48     best_parameters = grid_search.best_estimator_.get_params()\n     49     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...]\n        self.param_grid = {'clf__max_depth': (150, 155, 160), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul 01 15:09:02 2017\nPID: 17600               Python 2.7.13: C:\\ProgramData\\Anaconda2\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 806,  807,  808, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), 1, {'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 806,  807,  808, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), 1, {'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 806,  807,  808, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...32, 840, 846, 847, 852, 859, 865, 874, 887, 890]), verbose=1, parameters={'clf__max_depth': 150, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rt=False, random_state=None, splitter='best'))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method DecisionTreeClassifier.fit of Deci...esort=False, random_state=None, splitter='best')>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1639 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], sample_weight=None, check_input=True, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...resort=False, random_state=None, splitter='best'), X=array([[ 77.        ,  77.        ,   1.        ...       0.        ,   0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('data/ad.data', header=None)\n",
    "    explanatory_variable_columns = set(df.columns.values)\n",
    "    response_variable_column = df[len(df.columns.values)-1]\n",
    "    \n",
    "    # The last column describes the targets\n",
    "    explanatory_variable_columns.remove(len(df.columns.values)-1)\n",
    "    \n",
    "    # Encode advertisment as positive class and content as negative class\n",
    "    y = [1 if e == 'ad.' else 0 for e in response_variable_column]\n",
    "    X = df[list(explanatory_variable_columns)]\n",
    "    \n",
    "    '''\n",
    "    More than one quarter of the instances are missing at least one of the values\n",
    "    for the image's dimensions. These missing values are marked by whitespace and a\n",
    "    question mark. We replaced the missing values with negative one, but we could have\n",
    "    imputed the missing values; for instance, we could have replaced the missing height\n",
    "    values with the average height value:\n",
    "    '''\n",
    "    X.replace(to_replace=' *\\?', value=-1, regex=True, inplace=True)\n",
    "    \n",
    "    # Split data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # set the criterion keyword argument to entropy to build the tree \n",
    "    # using the informationgain heuristic\n",
    "    pipeline = Pipeline([('clf', DecisionTreeClassifier(criterion='entropy'))])\n",
    "    \n",
    "    # specify hyperparameters for grid search\n",
    "    parameters = {\n",
    "            'clf__max_depth': (150, 155, 160),\n",
    "            'clf__min_samples_split': (1, 2, 3),\n",
    "            'clf__min_samples_leaf': (1, 2, 3)\n",
    "            }\n",
    "    \n",
    "    # set GridSearchCV to maximise the models f1 score\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print 'Best score: %0.3f' % grid_search.best_score_\n",
    "    print 'Best parameters set:'\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "        \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print classification_report(y_test, predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['99A14FBC9F5F453C90E5BD8018ADA22D']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['99A14FBC9F5F453C90E5BD8018ADA22D'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.If object>], cell_name='<ipython-input-4-567e9303e245>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>\n        result = <ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>, result=<ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1        2    3     4     5     6   ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1        2    3     4     5     6   ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Satvik Sachdev\\Documents\\GitHub\\Machine Learning\\Mastering Machine Learning with Scikit Learn\\Chapter 5 Nonlinear Classification and Regression with Decision Trees\\<ipython-input-4-567e9303e245> in <module>()\n     41         'clf__min_samples_split': (1, 2, 3),\n     42         'clf__min_samples_leaf': (1, 2, 3)\n     43         }\n     44     # set GridSearchCV to maximise the models f1 score\n     45     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n---> 46     grid_search.fit(X_train, y_train)\n     47     print 'Best score: %0.3f' % grid_search.best_score_\n     48     print 'Best parameters set:'\n     49     best_parameters = grid_search.best_estimator_.get_params()\n     50     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...]\n        self.param_grid = {'clf__max_depth': (50, 150, 250), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3), 'clf__n_estimators': (5, 10, 20, 50)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul 01 15:11:37 2017\nPID: 4688                Python 2.7.13: C:\\ProgramData\\Anaconda2\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], make_scorer(f1_score), array([ 813,  814,  815, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], make_scorer(f1_score), array([ 813,  814,  815, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 813,  814,  815, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1124529390, splitter='best')>\n        X = array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 2.,  2.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 2.,  2.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 2.,  2.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-567e9303e245>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# set GridSearchCV to maximise the models f1 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m                 for train, test in cv)\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 00000000026BECB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\ProgramDa...conda2\\lib\\site-packages\\ipykernel\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['99A14FBC9F5F453C90E5BD8018ADA22D']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['99A14FBC9F5F453C90E5BD8018ADA22D'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 1, 22, 11, 26, 173000, tzinfo=tzutc()), u'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', u'msg_type': u'execute_request', u'session': u'99A14FBC9F5F453C90E5BD8018ADA22D', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'560B17249AB04CB28F5D788CB6FEFC76', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.If object>], cell_name='<ipython-input-4-567e9303e245>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>\n        result = <ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>, result=<ExecutionResult object at 5d6dc18, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000FB66630, file \"<ipython-input-4-567e9303e245>\", line 9>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1        2    3     4     5     6   ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u'print \"g\"', u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \", u\"import pandas as pd\\nfrom sklearn.tree import ...fication_report(y_test, predictions)\\n    \\n    \"], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1        2    3     4     5     6   ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': '', ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Satvik Sachdev\\Documents\\GitHub\\Machine Learning\\Mastering Machine Learning with Scikit Learn\\Chapter 5 Nonlinear Classification and Regression with Decision Trees\\<ipython-input-4-567e9303e245> in <module>()\n     41         'clf__min_samples_split': (1, 2, 3),\n     42         'clf__min_samples_leaf': (1, 2, 3)\n     43         }\n     44     # set GridSearchCV to maximise the models f1 score\n     45     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n---> 46     grid_search.fit(X_train, y_train)\n     47     print 'Best score: %0.3f' % grid_search.best_score_\n     48     print 'Best parameters set:'\n     49     best_parameters = grid_search.best_estimator_.get_params()\n     50     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...]\n        self.param_grid = {'clf__max_depth': (50, 150, 250), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3), 'clf__n_estimators': (5, 10, 20, 50)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jul 01 15:11:37 2017\nPID: 4688                Python 2.7.13: C:\\ProgramData\\Anaconda2\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], make_scorer(f1_score), array([ 813,  814,  815, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], make_scorer(f1_score), array([ 813,  814,  815, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 813,  814,  815, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 834, 835, 841, 851, 859, 863,\n       870, 873]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method RandomForestClassifier.fit of Rand...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...False, random_state=1124529390, splitter='best')>\n        X = array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 2.,  2.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 2.,  2.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...=False, random_state=1124529390, splitter='best'), X=array([[  -1.        ,   -1.        ,   -1.     ...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 1.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 2.,  2.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('data/ad.data', header=None)\n",
    "    explanatory_variable_columns = set(df.columns.values)\n",
    "    response_variable_column = df[len(df.columns.values)-1]\n",
    "    \n",
    "    # The last column describes the targets\n",
    "    explanatory_variable_columns.remove(len(df.columns.values)-1)\n",
    "    \n",
    "    # Encode advertisment as positive class and content as negative class\n",
    "    y = [1 if e == 'ad.' else 0 for e in response_variable_column]\n",
    "    X = df[list(explanatory_variable_columns)]\n",
    "    \n",
    "    '''\n",
    "    More than one quarter of the instances are missing at least one of the values\n",
    "    for the image's dimensions. These missing values are marked by whitespace and a\n",
    "    question mark. We replaced the missing values with negative one, but we could have\n",
    "    imputed the missing values; for instance, we could have replaced the missing height\n",
    "    values with the average height value:\n",
    "    '''\n",
    "    X.replace(to_replace=' *\\?', value=-1, regex=True, inplace=True)\n",
    "    \n",
    "    # Split data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # set the criterion keyword argument to entropy to build the tree \n",
    "    # using the informationgain heuristic\n",
    "    pipeline = Pipeline([('clf', RandomForestClassifier(criterion='entropy'))])\n",
    "    \n",
    "    # specify hyperparameters for grid search\n",
    "    parameters = {\n",
    "        'clf__n_estimators': (5, 10, 20, 50),\n",
    "        'clf__max_depth': (50, 150, 250),\n",
    "        'clf__min_samples_split': (1, 2, 3),\n",
    "        'clf__min_samples_leaf': (1, 2, 3)\n",
    "        }\n",
    "    # set GridSearchCV to maximise the models f1 score\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print 'Best score: %0.3f' % grid_search.best_score_\n",
    "    print 'Best parameters set:'\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "        \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print classification_report(y_test, predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
