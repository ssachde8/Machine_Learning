{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 2, Linear Regression, we discussed simple linear regression, multiple\n",
    "linear regression, and polynomial regression. These models are special cases of the\n",
    "generalized linear model, a flexible framework that requires fewer assumptions\n",
    "than ordinary linear regression. In this chapter, we will discuss some of these\n",
    "assumptions as they relate to another special case of the generalized linear model\n",
    "called logistic regression.\n",
    "Unlike the models we discussed previously, logistic regression is used for classification\n",
    "tasks. Recall that the goal in classification tasks is to find a function that maps an\n",
    "observation to its associated class or label. A learning algorithm must use pairs of\n",
    "feature vectors and their corresponding labels to induce the values of the mapping\n",
    "function's parameters that produce the best classifier, as measured by a particular\n",
    "performance metric. In binary classification, the classifier must assign instances to one\n",
    "of the two classes. Examples of binary classification include predicting whether or not\n",
    "a patient has a particular disease, whether or not an audio sample contains human\n",
    "speech, or whether or not the Duke men's basketball team will lose in the first round\n",
    "of the NCAA tournament. In multiclass classification, the classifier must assign one\n",
    "of several labels to each instance. In multilabel classification, the classifier must assign\n",
    "a subset of the labels to each instance. In this chapter, we will work through several\n",
    "classification problems using logistic regression, discuss performance measures for the\n",
    "classification task, and apply some of the feature extraction techniques you learned in\n",
    "the previous chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Binary Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some problems the response variable is not normally distributed. For instance,\n",
    "a coin toss can result in two outcomes: heads or tails. The Bernoulli distribution\n",
    "describes the probability distribution of a random variable that can take the positive\n",
    "case with probability P or the negative case with probability 1-P. If the response\n",
    "variable represents a probability, it must be constrained to the range {0,1}. Linear\n",
    "regression assumes that a constant change in the value of an explanatory variable\n",
    "results in a constant change in the value of the response variable, an assumption\n",
    "that does not hold if the value of the response variable represents a probability.\n",
    "Generalized linear models remove this assumption by relating a linear combinationOrdinary linear regression assumes that the response variable is normally distributed.\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is a\n",
    "function that describes the probability that an observation will have a value between\n",
    "any two real numbers. Normally distributed data is symmetrical. That is, half of the\n",
    "values are greater than the mean and the other half of the values are less than the\n",
    "mean. The mean, median, and mode of normally distributed data are also equal.\n",
    "\n",
    "In some problems the response variable is not normally distributed. For instance,\n",
    "a coin toss can result in two outcomes: heads or tails. The Bernoulli distribution\n",
    "describes the probability distribution of a random variable that can take the positive\n",
    "case with probability P or the negative case with probability 1-P. If the response\n",
    "variable represents a probability, it must be constrained to the range {0,1}. Linear\n",
    "regression assumes that a constant change in the value of an explanatory variable\n",
    "results in a constant change in the value of the response variable, an assumption\n",
    "that does not hold if the value of the response variable represents a probability.\n",
    "Generalized linear models remove this assumption by relating a linear combination\n",
    "\n",
    "In logistic regression, the response variable describes the probability that the outcome\n",
    "is the positive case. If the response variable is equal to or exceeds a discrimination\n",
    "threshold, the positive class is predicted; otherwise, the negative class is predicted. The\n",
    "response variable is modeled as a function of a linear combination of the explanatory\n",
    "variables using the logistic function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spam Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first problem is a modern version of the canonical binary classification problem:\n",
    "spam classification. In our version, however, we will classify spam and ham SMS\n",
    "messages rather than e-mail. We will extract TF-IDF features from the messages using\n",
    "techniques you learned in Chapter 3, Feature Extraction and Preprocessing, and classify\n",
    "the messages using logistic regression.\n",
    "\n",
    "We will use the SMS Spam Classification Data Set from the UCI Machine Learning\n",
    "Repository. The dataset can be downloaded from \n",
    "http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataseet, calculate basic summary statistics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary label and a text message comprise each row. The data set contains 5,574\n",
    "instances; 4,827 messages are ham and the remaining 747 messages are spam. The\n",
    "ham messages are labeled with zero, and the spam messages are labeled with one.\n",
    "While the noteworthy, or case, outcome is often assigned the label one and the\n",
    "non-case outcome is often assigned zero, these assignments are arbitrary. Inspecting\n",
    "the data may reveal other attributes that should be captured in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some predictions using scikit-learn's LogisticRegression class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    " \n",
    "df = pd.read_csv('SMSSpamCollection', delimiter='\\t',header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1],df[0])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit training messages, transform training & test messages\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ham. Message: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression and train our model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "for i, prediction in enumerate(predictions[:1]):\n",
    "    print 'Prediction: %s. Message: %s' % (prediction, X_test_raw[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does our classifier perform? The performance metrics we used for linear\n",
    "regression are inappropriate for this task. We are only interested in whether the\n",
    "predicted class was correct, not how far it was from the decision boundary. In the\n",
    "next section, we will discuss some performance metrics that can be used to evaluate\n",
    "binary classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary Classification Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAD3CAYAAAAOh6G5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xed8d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred, y_true = [0, 1, 1, 0], [1, 1, 1, 1]\n",
    "print 'Accuracy:', accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956447296794 [ 0.965311    0.96291866  0.95334928  0.95095694  0.9497006 ]\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression.score() predicts and scores labels for a test set using\n",
    "# accuracy. Let's evaluate our classifier's accuracy:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', delimiter='\\t',header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print np.mean(scores), scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(classifier, X_train, y_train, cv=5, scoring='precision')\n",
    "print 'Precision', np.mean(precisions), precisions\n",
    "recalls = cross_val_score(classifier, X_train, y_train, cv=5,scoring='recall')\n",
    "print 'Recalls', np.mean(recalls), recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. F1 Score / F Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
    "print 'F1', np.mean(f1s), f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ROC AUC - Receiver Operating Characteristic, or ROC curve,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', delimiter='\\t',header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict_proba(X_test)\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test,predictions[:, 1])\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Tuning Models with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4608 out of 4608 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.985\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__penalty: 'l2'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 10000\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__stop_words: None\n",
      "\tvect__use_idf: True\n",
      "Accuracy: 0.987078248385\n",
      "Precision:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array(['ham', 'spam'], \n      dtype='|S4')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c663afa91297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Recall:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-c663afa91297>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Precision:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Recall:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1240\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1012\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[1;32m-> 1014\u001b[1;33m                                      (pos_label, present_labels))\n\u001b[0m\u001b[0;32m   1015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label: array(['ham', 'spam'], \n      dtype='|S4')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                        ('vect', TfidfVectorizer(stop_words='english')),\n",
    "                        ('clf', LogisticRegression())\n",
    "                    ])\n",
    "parameters = {\n",
    "                'vect__max_df': (0.25, 0.5, 0.75),\n",
    "                'vect__stop_words': ('english', None),\n",
    "                'vect__max_features': (2500, 5000, 10000, None),\n",
    "                'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "                'vect__use_idf': (True, False),\n",
    "                'vect__norm': ('l1', 'l2'),\n",
    "                'clf__penalty': ('l1', 'l2'),\n",
    "                'clf__C': (0.01, 0.1, 1, 10),\n",
    "                }\n",
    "\n",
    "def main():\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,verbose=1, scoring='accuracy', cv=3)\n",
    "    df = pd.read_csv('SMSSpamCollection', delimiter='\\t',header=None)\n",
    "    X, y, = df[1], df[0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print 'Best score: %0.3f' % grid_search.best_score_\n",
    "    print 'Best parameters set:'\n",
    "    \n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "    \n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print 'Accuracy:', accuracy_score(y_test, predictions)\n",
    "    print 'Precision:', precision_score(y_test, predictions)\n",
    "    print 'Recall:', recall_score(y_test, predictions)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PhraseId      156060\n",
      "SentenceId    156060\n",
      "Phrase        156060\n",
      "Sentiment     156060\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Explore the data\n",
    "df = pd.read_csv('movie-reviews/train.tsv', header=0, delimiter='\\t')\n",
    "print df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n"
     ]
    }
   ],
   "source": [
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A series of escapades demonstrating the adage ...\n",
      "1    A series of escapades demonstrating the adage ...\n",
      "2                                             A series\n",
      "3                                                    A\n",
      "4                                               series\n",
      "5    of escapades demonstrating the adage that what...\n",
      "6                                                   of\n",
      "7    escapades demonstrating the adage that what is...\n",
      "8                                            escapades\n",
      "9    demonstrating the adage that what is good for ...\n",
      "Name: Phrase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df['Phrase'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    156060.000000\n",
      "mean          2.063578\n",
      "std           0.893832\n",
      "min           0.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           4.000000\n",
      "Name: Sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['Sentiment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    79582\n",
      "3    32927\n",
      "1    27273\n",
      "4     9206\n",
      "0     7072\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.622\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "# Train classofier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "global grid_search\n",
    "def main():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(stop_words='english')),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.25, 0.5),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'vect__use_idf': (True, False),\n",
    "        'clf__C': (0.1, 1, 10),\n",
    "    }\n",
    "    df = pd.read_csv('movie-reviews/train.tsv', header=0, delimiter='\\t')\n",
    "    X, y = df['Phrase'], df['Sentiment'].as_matrix()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print 'Best score: %0.3f' % grid_search.best_score_\n",
    "    print 'Best parameters set:'\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "    \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with binary classification, confusion matrices are useful for visualizing the types\n",
    "of errors made by the classifier. Precision, recall, and F1 score can be computed for\n",
    "each of the classes, and accuracy for all of the predictions can also be calculated.\n",
    "Let's evaluate our classifier's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "print 'Accuracy:', accuracy_score(y_test, predictions)\n",
    "print 'Confusion Matrix:', confusion_matrix(y_test, predictions)\n",
    "print 'Classification Report:', classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make predictions using the best parameter set found by using grid searching.\n",
    "While our classifier is an improvement over the baseline classifier, it frequently\n",
    "mistakes Somewhat Positive and Somewhat Negative for Neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
